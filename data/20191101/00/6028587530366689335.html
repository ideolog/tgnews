<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.forbes.com/sites/cognitiveworld/2019/10/31/should-we-be-afraid-of-ai/"/>
    <meta property="og:site_name" content="Forbes"/>
    <meta property="article:published_time" content="2019-11-01T00:00:00+00:00"/>
    <meta property="og:title" content="Should We Be Afraid of AI?"/>
    <meta property="og:description" content="If AI is transformative, then it has the power to be transformative both for good reasons as well as bad. So, is AI something we should be scared of?"/>
  </head>
  <body>
    <article>
      <h1>Should We Be Afraid of AI?</h1>
      <address><time datetime="2019-11-01T00:00:00+00:00">01 Nov 2019</time> by <a rel="author">Ron Schmelzer</a></address>
      <figure>
        <img src="https://specials-images.forbesimg.com/imageserve/1129149103/960x0.jpg?fit=scale"/>
        <figcaption>Is AI something to fear?<cite>Getty</cite></figcaption>
      </figure>
      <p>Recently major names in the technology industry have been talking about why the potential applications of artificial intelligence could be something we should be worried about. Their argument comes from two different places. One the one hand, they see AI as one of the most fundamental transformative technologies that we have ever seen in the history of mankind, and on the other hand, that transformative power is something we should be scared of and be wary about. If AI is transformative, then it has the power to be transformative both for good reasons as well as bad. However, fear of the unknown has always been the case with technology from the wheel to the internet. So, <a href="https://www.cognilytica.com/2017/09/13/ai-today-podcast-002-should-we-be-scared-of-ai/">is AI something we should be scared of</a>? The fears of AI seem to stem from a few common causes: general anxiety about machine intelligence, the fear of mass unemployment, concerns about super-intelligence, putting the power of AI into the wrong people’s hands, and general concern and caution when it comes to new technology.</p>
      <p>
        <b>General Anxiety about AI</b>
      </p>
      <p>One of the most widespread fears of AI is just general anxiety about it and what it’s potentially capable of. A recurring theme in movies and science fiction is AI systems that go rogue - think HAL from 2001: A Space Odyssey or the Terminator movie series. People don’t like machines that get too smart, because we fear we can’t control it. This popular representation of AI gone bad is causing a general wariness in the public surrounding the development of intelligent systems technologies. The fear is generally surrounding the unknown that as AI systems are becoming more intelligent and human intelligence surrounding these systems is increasing, these two unknowns don’t really give us a clear direction for where things could go. </p>
      <p>However, just as we have examples of HAL and Terminator, we also have examples as C3PO and the computers from Star Trek. These are highly intelligent systems that are well within the control of humans. <a href="https://www.cognilytica.com/2018/03/15/the-ai-enabled-future/">The future could be as great and benign as Star Trek </a>if we had that perspective on the possibilities of intelligent machines. A good antidote to general anxiety is the realization that whenever human society has faced a major change or shift due to technological advances, humans has developed and adapted right along with it.</p>
      <p>
        <b>Fear of AI: AI is a Job Killer</b>
      </p>
      <p><a href="https://www.cognilytica.com/2018/04/13/ai-is-not-a-job-killer-its-a-job-category-killer/">Another major fear of AI is rooted in the idea of mass unemployment of human workers due to their replacement by AI workers.</a> A big concern is that in the previous wave of automation, it was mostly blue collar jobs like manufacturing oriented jobs that were automated away, but in this new wave, it will be mostly white collar service-oriented jobs that are based around knowledge workers that will bear the brunt of intelligent forms of automation. The need for trained human workers in many areas of the economy will go away as the use of AI grows and increasingly permeates the business world. AI also has an effect on blue collar workers such as delivery drivers, cab drivers and many more aspects of supply chain, logistics, and manufacturing. The fact is the technology is in place that 80% of any of these jobs can be done by machines that are smart enough, so the reality already exists. </p>
      <p>The counterargument here is that some of these systems aren’t to a point where they can reliably replace many human jobs. While AI systems provide a lot of capabilities, they simply can’t operate in a fully autonomous mode. In fact, most successful AI implementations are being done such that the AI system is providing an augmented intelligence role, supporting the human at what they do best, and not fully replacing them. In general, as technology waves disrupt industries and workers, they replace job categories, but don’t take away overall jobs. In fact overall jobs continue to grow and find new niches while machines simply replace the old ways of doing things. Companies aren’t completely throwing things out that have been working for them. It’s a more general transition into the world of new technologies such as AI. As is often said, AI isn’t a job killer, it’s a job category killer.</p>
      <p>The fact is that a lot of industries are already being disrupted by the advancement of technology and a lot of it has nothing to do with AI. Rather, it is due to automation and streamlining processes that make it easier and quicker to go about inputting work for ourselves and not relying on businesses and other organizations to be the middleman when it comes to getting things done.</p>
      <p>
        <b>Fear of AI: Bad People Doing Bad Things</b>
      </p>
      <p>Another common fear of AI is that bad actors can do bad things when it comes to AI. Leaders in Russia made a pronouncement that whoever leads the advancement of AI is going to be one of the top rulers of the world. I<a href="https://www.cognilytica.com/2018/08/21/the-race-for-ai-dominance-is-more-global-than-you-think/">t is no surprise that countries are pouring significant amounts of investment and research</a> into developing AI systems from everything to military advancement to intelligence systems that can influence the news. We can expect governments to continue to use AI systems in ways that will make us increasingly uncomfortable in the ways they are applied to warfare, surveillance, law enforcement, and other purposes. </p>
      <p>Yet, while we can expect governments and countries to compete with each other for AI dominance, it’s not the governments we have to fear. After all, laws and governance are there to keep an eye on government behavior. We have more to fear from bad actors, criminals, and mischief makers taking AI technologies and bending them to their ill-conceived purposes. As AI systems tend to learn from their creators, that can call into question the intention of the creator and those who are teaching the systems and what all they hope to accomplish. The fear is all stemming from the unknown. In addition, there hasn’t really been a strong counter argument as to what could be the best way to approach this particular scenario and what it means for the future.</p>
      <p>
        <b>Fear of AI: The SuperIntelligence</b>
      </p>
      <p>Probably the biggest fear of AI making media waves is that of super intelligence or that AI will reach a point where it doesn’t care for or about the existence of humanity anymore, such as what happens with Skynet in the Terminator series of movies. The technology will get to a point where it can teach itself and improve and invent on its own, and instead of becoming a force for the betterment of humanity, humanity becomes a servant of technology. The fear is that our brains will just not be able to keep up with advancement, development and invention after a certain point because things will be moving way too fast.</p>
      <p>Computing systems could very well reach a point where they outstrip their human creators, and what will that mean for humanity when we reach that point? It makes us question what exactly intelligence is, and how we measure and define intelligence as concept for both humanity and computers, and how that new definition will fit into the world both now and moving forward. But all of this is assuming that systems can and will be able to achieve the goal of Artificial General Intelligence (AGI) and that we as a species or a society will not be able to put safeguards in place to keep the computers from reaching that point.</p>
      <p>The big counterargument to all of this is that we are still much farther away from achieving AGI than we really think we are. While a lot of the technology is moving quickly to realizing goals of narrow AI, there are parts that aren’t working particularly well. Data is still the cornerstone of AI, and a lot of it is still messy and dirty — the <a href="https://www.forbes.com/sites/cognitiveworld/2019/03/07/the-achilles-heel-of-ai/">Achilles Heel of AI</a>.</p>
      <p>All of these fears boil down to the fact that we just don’t know where AI is going and how soon it will take us to get there. Technology makes surprising and unusual leaps and bounds in ways we never think it will and things we think will take a while don’t. On the other hand things we thought would be here sooner aren’t there yet. It’s just a situation where we have to wait and see what comes.</p>
    </article>
  </body>
</html>